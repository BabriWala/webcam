The error Cannot read properties of null (reading 'videoWidth') occurs because videoRef.current is likely null when you try to access videoRef.current.videoWidth. This is likely happening because the videoRef is either not yet attached to the DOM or the video element hasn't started loading or playing when you try to read its dimensions.

Causes of this error:

1. Video element not yet mounted: If you're trying to access the videoWidth immediately after setting srcObject, the video element might not have loaded its metadata yet.


2. Race condition: The video element's metadata (like videoWidth and videoHeight) might not be available right after srcObject is set.



Solution:

To avoid this issue, you need to ensure that the video has fully loaded and its metadata (such as videoWidth and videoHeight) is available before you attempt to access it.

You can do this by listening for the loadedmetadata event, which is triggered once the metadata (such as video dimensions) is available.

Updated Code:

Hereâ€™s how you can modify your code to handle this error:

import { useState, useRef, useEffect } from "react";

function App() {
  const videoRef = useRef(null);
  const processedDisplayRef = useRef(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [currentStream, setCurrentStream] = useState(null);

  // Function to start attendance and initiate frame capture
  const handleStartAttendance = async () => {
    try {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert("Camera API not supported by this browser.");
        return;
      }

      // Access the camera stream
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      setCurrentStream(stream);

      // Ensure videoRef is not null before setting the stream
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.style.display = "none"; // Hide the video for UI

        // Wait for the video metadata to be loaded
        videoRef.current.onloadedmetadata = () => {
          if (processedDisplayRef.current) {
            processedDisplayRef.current.width = videoRef.current.videoWidth;
            processedDisplayRef.current.height = videoRef.current.videoHeight;
          }

          // Start processing frames after metadata is loaded
          setIsProcessing(true);
        };
      }
    } catch (err) {
      console.error("Error accessing camera:", err);
    }
  };

  // Function to end attendance and stop camera stream
  const handleEndAttendance = () => {
    if (currentStream) {
      setIsProcessing(false);
      currentStream.getTracks().forEach((track) => track.stop());
      if (videoRef.current) {
        videoRef.current.srcObject = null;
      }

      // Clear the canvas when stopping
      const ctx = processedDisplayRef.current?.getContext("2d");
      if (ctx) {
        ctx.clearRect(0, 0, processedDisplayRef.current.width, processedDisplayRef.current.height);
      }
    }
  };

  // Function to process frames: Capture images and send to API
  const processFrames = async () => {
    if (!isProcessing || !videoRef.current) return;

    try {
      // Create canvas and draw video frame onto it
      const canvas = document.createElement("canvas");
      canvas.width = videoRef.current.videoWidth;
      canvas.height = videoRef.current.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(videoRef.current, 0, 0);

      // Convert the frame to base64
      const imageData = canvas.toDataURL("image/png").replace(/^data:image\/(png|jpg);base64,/, "");

      // Send image data to the server
      const response = await fetch("https://192.168.0.124:5000/app0/api/predict", {
        method: "POST",
        body: JSON.stringify({ image: imageData }),
        headers: { "Content-Type": "application/json" },
      });

      if (!response.ok) {
        throw new Error("Network response was not ok.");
      }

      // Processed image received from the API
      const data = await response.json();
      const processedImage = new Image();
      processedImage.onload = () => {
        const ctx = processedDisplayRef.current?.getContext("2d");
        if (ctx) {
          ctx.clearRect(0, 0, processedDisplayRef.current.width, processedDisplayRef.current.height);
          ctx.drawImage(processedImage, 0, 0);
        }

        // Continue processing if still active
        if (isProcessing) {
          requestAnimationFrame(processFrames); // Continue frame processing
        }
      };
      processedImage.src = `data:image/png;base64,${data.image}`;
    } catch (error) {
      console.error("Error in processFrames:", error);
    }
  };

  // useEffect to handle frame processing continuously when isProcessing is true
  useEffect(() => {
    if (isProcessing) {
      processFrames(); // Start processing when isProcessing becomes true
    }

    // Cleanup when processing stops
    return () => {
      setIsProcessing(false);
      if (currentStream) {
        currentStream.getTracks().forEach((track) => track.stop());
      }
      if (videoRef.current) {
        videoRef.current.srcObject = null;
      }

      // Clear canvas
      const ctx = processedDisplayRef.current?.getContext("2d");
      if (ctx) {
        ctx.clearRect(0, 0, processedDisplayRef.current.width, processedDisplayRef.current.height);
      }
    };
  }, [isProcessing]); // Re-run the effect when isProcessing changes

  return (
    <div className="min-h-screen bg-gray-100 flex items-center justify-center p-4">
      <div className="max-w-lg w-full bg-white p-8 rounded-lg shadow-lg">
        <h1 className="text-2xl font-semibold text-center mb-4">Attendance Monitoring</h1>

        {/* Canvas to display the processed image */}
        <div className="flex justify-center mb-4">
          <canvas
            ref={processedDisplayRef}
            className="border border-gray-300 shadow-sm"
          />
        </div>

        {/* Buttons to start and end attendance */}
        <div className="flex justify-between">
          <button
            onClick={handleStartAttendance}
            className={`px-6 py-3 bg-blue-500 text-white rounded-md transition-all duration-300 ${isProcessing ? 'opacity-50 cursor-not-allowed' : ''}`}
            disabled={isProcessing}
          >
            Start Attendance
          </button>

          <button
            onClick={handleEndAttendance}
            className={`px-6 py-3 bg-red-500 text-white rounded-md transition-all duration-300 ${!isProcessing ? 'opacity-50 cursor-not-allowed' : ''}`}
            disabled={!isProcessing}
          >
            End Attendance
          </button>
        </div>
      </div>
    </div>
  );
}

export default App;

Key Changes:

1. Wait for loadedmetadata event:

After setting videoRef.current.srcObject = stream, we wait for the loadedmetadata event to fire, which indicates that the video element has loaded its metadata (including videoWidth and videoHeight).

Once onloadedmetadata is triggered, we set the canvas size and start the frame processing.


videoRef.current.onloadedmetadata = () => {
  if (processedDisplayRef.current) {
    processedDisplayRef.current.width = videoRef.current.videoWidth;
    processedDisplayRef.current.height = videoRef.current.videoHeight;
  }

  // Start processing frames after metadata is loaded
  setIsProcessing(true);
};


2. Accessing videoWidth safely:

By waiting for the loadedmetadata event, we ensure that videoRef.current.videoWidth and videoRef.current.videoHeight are available before we try to access them.




Explanation:

onloadedmetadata: This event is fired once the metadata for a video (like its dimensions) is fully loaded. We listen for this event before accessing videoWidth and videoHeight to avoid the error that occurs when trying to read these properties too early.

Video Stream Handling: The stream is only assigned to the videoRef after the metadata has been loaded, which ensures that when you attempt to get the videoWidth, it is a valid value.


Conclusion:

By listening for the loadedmetadata event, you ensure that the video element's metadata (such as width and height) is fully available before trying to access these properties. This avoids the null reference error when trying to read videoWidth.

